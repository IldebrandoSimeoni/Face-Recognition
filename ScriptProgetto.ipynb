{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScriptProgetto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j4GEftCpsvh"
      },
      "source": [
        "#Progetto ESM\n",
        "#Riconoscimento di volti\n",
        "Gruppo 7\n",
        "\n",
        "Simeoni Ildebrando\n",
        "\n",
        "Scanu Mario\n",
        "\n",
        "Marescalco Christian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbvO4I8d70mZ"
      },
      "source": [
        "%reset -f\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga5oDm5cCzMl"
      },
      "source": [
        "##Download dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsAPmKY5C1m8"
      },
      "source": [
        "%cd /content/drive/MyDrive/esm/immagini\n",
        "!pwd\n",
        "!unzip img_align_celeba.zip  -d /content/drive/MyDrive/esm/immagini/img_align_celeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duuLIyyvDET7"
      },
      "source": [
        "##Creazione file csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkOrTKVFDHBO"
      },
      "source": [
        "data = np.genfromtxt(\"/content/drive/MyDrive/esm/identity_CelebA.txt\",delimiter=\" \").T  \n",
        "'''genfromtxt ritorna un ndarray (array di dimensione N); .T ne fa la trasposta,\n",
        "in modo da avere una matrice 2x202599, avente sulla prima riga tutti i nomi \n",
        "delle immagini e sulla seconda le relative identità'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOYYeVgSDulZ"
      },
      "source": [
        "###Calcolo delle 1000 identità più presenti nel dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqbLpCRYDlXJ"
      },
      "source": [
        "data = np.delete(data,(0),axis=0) #eliminiamo la prima riga formata dai nomi delle immagini\n",
        "const = data.shape[1] #numero delle identità (ripetute), pari al numero di immagini presenti nel dataset (202599)\n",
        "data = np.reshape(data,(const)) #in questo caso reshape da come risultato un array monodimensionale di lunghezza const, che non più un array 1x202599 ma un vettore\n",
        "identita_counter = {} #conteggio delle volte in cui un'identità si ripete nelle annotazioni del dataset, è un dizionario perché poi facciamo il sort, in un dizionario python non ci sono valori duplicati, quindi sovrascriviamo elementi del dizionario (aventi stessa chiave (identita)) quando si ripetono, aventi stessa chiave, ma nuovo valore pari a quello precedente +1\n",
        "for identita in data:           #scorro l'array data di 202599 valori\n",
        "  if identita in identita_counter:  #incremento di uno del counter di una specifica identità ogni volta che si ripresenta nel dataset\n",
        "     identita_counter[identita] += 1 \n",
        "  else:\n",
        "    identita_counter[identita] = 1\n",
        "\n",
        "popular_identita = sorted(identita_counter, key = identita_counter.get, reverse = True) #effettuiamo il sorting decrescente (reverse=True) del dizionario sulla chiave 'identita_counter' che serve per confrontare gli elementi in base al loro numero di occorrenze nel dizionario \n",
        "top_1000 = popular_identita[:1000]  #vettore delle 1000 identità più ricorrenti nel dataset, i valori sono float perché identita_counter era float\n",
        "top_1000 = [int(i) for i in top_1000] #effettuo una conversione da float a interi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kgxnEAKEAKD"
      },
      "source": [
        "###Suddividisione delle immagini per ogni identità in immagini di training, validazione e test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHk2X3EEEJ1m"
      },
      "source": [
        "items = []    #lista di tutte le tuple,separate da parentesi tonde, del file identity celebA , in cui ogni tupla è formata da nome dell'immagine e relativa identità\n",
        "file = open('/content/identity_CelebA.txt','r') \n",
        "for line in file:\n",
        "    x, y = line.split() #divido ogni linea del file, che era una stringa, e ho in output due stringhe, la prima nome dell'immagine la seconda identita relativa;con separatore di default la stringa stessa, quindi divide in base allo spazio\n",
        "    items.append((x, int(y))) #appendo alla lista items, tuple formate da nome immagine e relativa identità (passata come un intero)\n",
        "\n",
        "img_per_identita = [] #lista di liste in cui ogni lista interna include tutte le tuple associate a una stessa identita\n",
        "img_per_training = []   # le seguenti sono liste di tuple\n",
        "img_per_validation = []\n",
        "img_per_test = []\n",
        "\n",
        "#inizio for\n",
        "for identita in top_1000:   #itero solo sulle 1000 identità più presenti nel dataset\n",
        "  img_identita = []  # singola sottolista della lista img_per_identita, formata da tuple associate a una stessa identita\n",
        "  for item in items:    #itero su tutte le tuple del file\n",
        "    if item[1]==identita:    #item[1] è il secondo elemento della singola tupla item appartenente alla lista di tuple items; rappresenta l'identita di quella particolare immagine, qui verifico se l'identità presa in riferimento è uguale a una del file che sto scorrendo \n",
        "      img_identita.append((item[0],identita))  #se il secondo elemento della tupla è una delle 1000 identita più presenti, allora aggiungo la tupla alla lista di tuple img_class\n",
        "  img_per_identita.append(img_identita) #append della sottolista img_identita alla lista di liste img_per_identita\n",
        "  \n",
        "  n = identita_counter[identita] #numero totale di immagini per la specifica identita su cui sto iterando presenti nel dataset, dizionario con key identita, che restituisce il numero di elementi del dizionario aventi quella key\n",
        "  n70 = int(70*n/100)   #suddivisione delle immagini di ognuna delle 1000 identita in 70/20/10\n",
        "  n20 = int(20*n/100)\n",
        "  n10 = int(10*n/100)\n",
        "  nresto = n-n70-n20-n10\n",
        "  n70 = n70+nresto #approssimazione per eccesso della percentuale di training\n",
        "\n",
        "  img_70 = img_identita[0:n70]\n",
        "  img_20 = img_identita[n70:n70+n20]\n",
        "  img_10 = img_identita[n70+n20:n70+n20+n10]\n",
        "\n",
        "  for img in img_70:      #per appendere le singole tuple del vettore img_70 una alla volta alla lista img_per_training (che è una lista di tuple)\n",
        "   img_per_training.append(img)\n",
        "  for img in img_20:\n",
        "   img_per_test.append(img)\n",
        "  for img in img_10:\n",
        "   img_per_validation.append(img)\n",
        "#fine for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEiOuwePEX4t"
      },
      "source": [
        "###Scrittura file csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwMFxJvFEaZA"
      },
      "source": [
        "import csv\n",
        "with open('/content/training.csv', 'w') as csvfile: #vedi documentazione cvwriter\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerows(img_per_training)\n",
        "    \n",
        "with open('/content/test.csv', 'w') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerows(img_per_test)\n",
        "\n",
        "with open('/content/validation.csv', 'w') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerows(img_per_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDV7YW0ZpfLB"
      },
      "source": [
        "##Preparazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNl9GbgN8jfc"
      },
      "source": [
        "img_rows = 224\n",
        "img_cols =224\n",
        "img_channels = 3\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "traindf=pd.read_csv('/content/drive/MyDrive/esm/csv/training.csv',dtype={'A':str,'B':str},names=['A','B']) #Read a comma-separated values (csv) file into DataFrame.\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,rotation_range=20,zoom_range =[0.9,1.2],width_shift_range=0.1,height_shift_range=0.1,preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe = traindf,\n",
        "                                                    directory='/content/drive/MyDrive/esm/immagini/img_align_celeba',\n",
        "                                                    target_size = (img_rows,img_cols),\n",
        "                                                    x_col='A',\n",
        "                                                    y_col='B',\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = 32\n",
        "                                                    ) \n",
        "\n",
        "\n",
        "validationdf=pd.read_csv('/content/drive/MyDrive/esm/csv/validation.csv',dtype={'A':str,'B':str},names=['A','B']) \n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255,preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_dataframe(dataframe = validationdf,\n",
        "                                                    directory='/content/drive/MyDrive/esm/immagini/img_align_celeba',\n",
        "                                                    target_size = (img_rows,img_cols),\n",
        "                                                    x_col='A',\n",
        "                                                    y_col='B',\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = 32\n",
        "                                                    ) \n",
        "\n",
        "testdf=pd.read_csv('/content/drive/MyDrive/esm/csv/test.csv',dtype={'A':str,'B':str},names=['A','B']) \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255,preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe = testdf,\n",
        "                                                    directory='/content/drive/MyDrive/esm/immagini/img_align_celeba',\n",
        "                                                    target_size = (img_rows,img_cols),\n",
        "                                                    x_col='A',\n",
        "                                                    y_col='B',\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=False,\n",
        "                                                    batch_size = 32\n",
        "                                                    ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYE2ZbSLrGuC"
      },
      "source": [
        "##Architettura\n",
        "ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ZXs9gRBi5c"
      },
      "source": [
        "model=tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation = \"softmax\"\n",
        ")\n",
        "\n",
        "opt= tf.keras.optimizers.Adam(learning_rate=0.0003, name=\"Adam\") \n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IIjHJtzrNi0"
      },
      "source": [
        "##Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS81LUeqC6fA"
      },
      "source": [
        "num_imm_train = len(train_generator.filenames)\n",
        "num_imm_val = len(validation_generator.filenames)\n",
        "batch_size = 32\n",
        "num_epoche = 15 \n",
        "\n",
        "model.fit(\n",
        "    x=train_generator,\n",
        "    y=None,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epoche,\n",
        "    verbose=1,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch=num_imm_train // batch_size,\n",
        "    validation_steps=num_imm_val//batch_size,\n",
        "    validation_batch_size=batch_size,\n",
        "    workers=10,\n",
        "    use_multiprocessing=True,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e28Pkm81rlSS"
      },
      "source": [
        "##Valutazione delle prestazioni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnHnx1oWaonD"
      },
      "source": [
        "###Valutazioni sull'intero test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzlSr50ZrZUF"
      },
      "source": [
        "pred = model.predict(test_generator) \n",
        "label = test_generator.classes  #classes variabile dell'oggetto test_generator,(rapp.sparsa),label è etichetta effettiva\n",
        "pred1=np.argmax(pred,1) #rapp sparsa,etichetta predetta\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "checonfusione = metrics.confusion_matrix(label,pred1)\n",
        "\n",
        "print(metrics.accuracy_score(label,pred1))\n",
        "print(metrics.confusion_matrix(label,pred1))\n",
        "\n",
        "plt.figure(1)\n",
        "plt.imshow(checonfusione,clim = None,cmap = 'jet')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7-5WTANaunW"
      },
      "source": [
        "###Valutazioni su singole immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZQeDkhZo3v"
      },
      "source": [
        "testsingole_datagen = ImageDataGenerator(rescale = 1./255,preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "test_generatorsingole = test2_datagen.flow_from_directory('/content/testsingole',\n",
        "                                                   target_size=(img_rows, img_cols),\n",
        "                                                   batch_size=1,\n",
        "                                                   class_mode='categorical')                                                                                                        \n",
        "\n",
        "pred = model.predict(test_generatorsingole)   \n",
        "pred1=np.argmax(pred,1)  \n",
        "print(pred1)\n",
        "\n",
        "#Top 3 prediction\n",
        "\n",
        "Top3 = np.sort(pred[0])[::-1]\n",
        "    \n",
        "print(pred[0].argsort()[-3:][::-1]) #Top 3 delle classi più probabili\n",
        "print(Top3[0:3])                    #Relative probabilità"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}